{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import functions.fn_stats as fn_stats\n",
    "import functions.fn_charts as fn_charts\n",
    "import params.consts as consts\n",
    "from sklearn.preprocessing import (OneHotEncoder, StandardScaler, MinMaxScaler, PowerTransformer,)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo o dataset tratado e visualizando o overview atual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(consts.DATASET_LEAN) # Armazenando o dataset tratado em uma variável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df # Exbindo uma visão geral do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # Visualizando a quantidade de linhas e colunas do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # Exibindo as informações das variáveis do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_stats.describe(df) # Usando a função que exibe as estatísticas das colunas numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(exclude='number') # Exibindo as estatísticas das colunas categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() # Somando todos os valores nulos de cada coluna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo os valores de x e y para o modelo de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('price', axis=1) # Definindo os valores de x para o modelo, separando a variável target do dataset\n",
    "y = df['price'] # Definindo os valores de y para o modelo, deixando o dataset somente com a variável target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head(3) # Visualizando os dados de x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(3) # Visualizando os dados de y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listando as variáveis numéricas e categóricas de x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = x.select_dtypes(include='number').columns # Armazenando as features numéricas em uma variável\n",
    "categorical_features = x.select_dtypes(exclude='number').columns # Armazenando as features categóricas em uma variável\n",
    "\n",
    "print('- Numerical Features:') # Printando as variávei numéricas\n",
    "for feature in numerical_features:\n",
    "    print(feature)\n",
    "\n",
    "print('\\n- Categorical Features:') # Printando as variávei categóricas\n",
    "for feature in categorical_features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando a distribuição das features de x em histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_charts.histplots(x, numerical_features, num_cols=7, height_figsize=2) # Criando os histplots para ver sua distribuição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo por qual procedimento cada feature de x vai passar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = [ # Definindo as colunas que vão passar por One Hot Encoder\n",
    "    'host_is_superhost', # Coluna categórica\n",
    "    'property_type', # Coluna categórica\n",
    "    'room_type', # Coluna categórica\n",
    "    'bed_type', # Coluna categórica\n",
    "    'instant_bookable', # Coluna categórica\n",
    "    'is_business_travel_ready', # Coluna categórica\n",
    "    'cancellation_policy', # Coluna categórica\n",
    "    'host_listings_count', # Coluna com inteiros discretos\n",
    "    'accommodates', # Coluna com inteiros discretos\n",
    "    'bathrooms', # Coluna com inteiros discretos\n",
    "    'bedrooms', # Coluna com inteiros discretos\n",
    "    'beds', # Coluna com inteiros discretos\n",
    "    'minimum_nights', # Coluna com inteiros discretos\n",
    "]\n",
    "\n",
    "power_cols = [ # Definindo as colunas que vão passar por Power Transformation\n",
    "   'extra_people', # Coluna com assimetria dos dados\n",
    "   'latitude', # Coluna com assimetria dos dados\n",
    "   'longitude', # Coluna com assimetria dos dados\n",
    "]\n",
    "\n",
    "min_max_cols = [ # Definindo as colunas que vão passar por Min-Max Scaler\n",
    "    'ano', # Coluna com distribuição uniforme dos dados\n",
    "    'mes', # Coluna com distribuição uniforme dos dados\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo os modelos de classificação que serão usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = { # Definindo os modelos de regressão que serão usados\n",
    "    'DummyRegressor': DummyRegressor(strategy='median'),  # Modelo base para referência\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(random_state=consts.RANDOM_STATE),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(n_neighbors=5),\n",
    "    'RandomForestRegressor': RandomForestRegressor(random_state=consts.RANDOM_STATE),\n",
    "    'ExtraTreesRegressor': ExtraTreesRegressor(random_state=consts.RANDOM_STATE),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a função com o pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline( # Função para fazer todo o procedimento de pipeline e validação cruzada, e retornar os scores\n",
    "    x, # Passando o x como parâmetro da função\n",
    "    y, # Passando o y como parâmetro da função\n",
    "    model, # Passando o modelo como parâmetro da função\n",
    "): \n",
    "\n",
    "    preprocessing = ColumnTransformer( # Estabelecendo os pré processamentos que serão aplicados nas features\n",
    "        [ # Passando a inicial do novo nome da coluna, o pré processamento que será aplicado e a lista de colunas para pré processamento\n",
    "            ('one_hot', OneHotEncoder(), one_hot_cols),\n",
    "            ('min_max', MinMaxScaler(), min_max_cols),\n",
    "            ('power', PowerTransformer(), power_cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline( # Criando o pipeline para o modelo de classificação (Pipeline do Imblearn para tratar o desbalanceamento do dataset)\n",
    "        [ # Passando as etapas do pipeline\n",
    "            ('pre_processing', preprocessing), # Fazendo o pré processamento conforme as definições anteriores\n",
    "            ('feature_selection', SelectKBest(score_func=f_regression, k=10)), # Selecionando as melhores features para o modelo\n",
    "            ('models', model), # Aplicando o modelo passado para a função\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    scores = cross_validate( # Fazendo a validação cruzada para testar diversas combinações de separação entre dados de treino e teste\n",
    "            # visando ter diversos valores para as métricas, e assim trabalhar com os valores médios ou mais frequentes\n",
    "        pipeline, # Passando o pipeline definido acima\n",
    "        x, # Passando o dataset x\n",
    "        y, # Passando o dataset y\n",
    "        cv=KFold(n_splits=5, shuffle=True, random_state=consts.RANDOM_STATE), # Aplicando o StratifiedKFold por ser um dataset \n",
    "            # desbalanceado, com um número inicial de 5 folds e aplicando o shuffle pois não se trata de um caso de séries temporais\n",
    "        scoring=['r2', 'neg_root_mean_squared_error'], # Definindo as métricas de avaliação dos modelos\n",
    "        n_jobs=-2, # Definindo para usar toda a capacidade de processamento do computador e deixar um processador livre para não travar\n",
    "    )\n",
    "\n",
    "    return scores # Retornando os scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando a função com o pipeline e armazenando os resultados de cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = { # Aplicando a função com o Pipeline, passando os datasets x, y e os modelos, e armazenando os resultados em uma variável\n",
    "    'DummyRegressor': pipeline(x, y, models['DummyRegressor']),\n",
    "    'LinearRegression': pipeline(x, y, models['LinearRegression']),\n",
    "    'DecisionTreeRegressor': pipeline(x, y, models['DecisionTreeRegressor']),\n",
    "    'KNeighborsRegressor': pipeline(x, y, models['KNeighborsRegressor']),\n",
    "    'RandomForestRegressor': pipeline(x, y, models['RandomForestRegressor']),\n",
    "    'ExtraTreesRegressor': pipeline(x, y, models['ExtraTreesRegressor']),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um dataset com os resultados dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in results.items(): # Criando uma estrutura de repetição para percorrer os resultados dos modelos\n",
    "    results[key]['time'] = results[key]['fit_time'] + results[key]['score_time'] # Criando a coluna de tempo somando fit_time e score_time\n",
    "\n",
    "df_results = pd.DataFrame(results).T.reset_index().rename(columns={'index': 'model'}) # Criando um df transposto com os resultados dos modelos\n",
    "\n",
    "df_results_explode = df_results.explode(df_results.columns[1:].to_list()).reset_index(drop=True) # Criando um df separando os maps por linhas\n",
    "\n",
    "df_results_explode # Exibindo o dataset com os resultados dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando os resultados dos modelos através de boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_charts.boxplots(df_results_explode, df_results.columns[3:].to_list(), 'model') # Criando os boxplots para avaliação dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando os resultados de cada modelo\n",
    "\n",
    "| Posição    | Accuracy              | Precision             | Recall                | ROC_AUC               | Average Precision     | Time                  |\n",
    "|------------|-----------------------|-----------------------|-----------------------|-----------------------|-----------------------|-----------------------|\n",
    "| Referência | Quanto maior melhor    | Quanto maior melhor    | Quanto maior melhor    | Quanto maior melhor    | Quanto maior melhor    | Quanto menor melhor    |\n",
    "| 1          | **LogisticRegression**     | **LogisticRegression**     | KNNClassifier          | **LogisticRegression**     | **LogisticRegression**     | **LogisticRegression**     |\n",
    "| 2          | KNNClassifier          | KNNClassifier          | **LogisticRegression**     | KNNClassifier          | KNNClassifier          | DummyClassifier        |\n",
    "| 3          | DecisionTreeClassifier | DecisionTreeClassifier | DecisionTreeClassifier | DecisionTreeClassifier | DecisionTreeClassifier | DecisionTreeClassifier |\n",
    "| 4          | DummyClassifier        | DummyClassifier        | DummyClassifier        | DummyClassifier        | DummyClassifier        | KNNClassifier          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo o modelo que será utilizado no projeto de classificação\n",
    "\n",
    "Após análise dos resultados de cada um dos modelos, é possível concluir que o modelo com os melhores resultados foi o de Logistic Regression, pois liderou os resultados nas métricas de Accuracy, Precision, ROC_AUC, Average Precision e Time, e ficou na segunda posição na métrica de Recall. Além disso, no caso de datasets desbalanceados como é o caso desse estudo, as principais métricas avaliadas são o ROC_AUC e o Average Precision, onde o modelo de Logistic Regression também obteve as melhores performances. E em relação ao processamento, esse modelo também teve a melhor performance com o menor tempo de processamento. \n",
    "\n",
    "Portando, diante de todo esse contexto, **o melhor modelo para ser usado no projeto é o Logistic Regression**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
